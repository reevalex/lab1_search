{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![LiU_logo.png](data:image/png;base64,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)\n",
        "## Linkoping University: TDDC17 Artificial Intelligence\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4NZ1cPpAtS_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lab5 : Deep Learning**\n",
        "\n",
        "**Lab5.3 :RNN-LSTM Implementation**\n",
        "\n",
        "  In this assignment, you will learn how to implement a RNN and LSTM for sequential data. We will use the deep learning library PyTorch, which is well-known for its ease of use\n",
        "\n",
        "The goal is to classify sequences.\n",
        "Elements and targets are represented locally (input vectors with only one non-zero bit).\n",
        "The sequence starts with an B, ends with a E (the “trigger symbol”), and otherwise consists of randomly chosen symbols from the set {a, b, c, d} except for two elements at positions t1 and t2 that are either X or Y.\n",
        "For the DifficultyLevel.HARD case, the sequence length is randomly chosen between 100 and 110, t1 is randomly chosen between 10 and 20, and t2 is randomly chosen between 50 and 60.\n",
        "There are 4 sequence classes Q, R, S, and U, which depend on the temporal order of X and Y.\n",
        "\n",
        "The rules are:\n",
        "\n",
        "- X, X -> Q,\n",
        "- X, Y -> R,\n",
        "- Y, X -> S,\n",
        "- Y, Y -> U.\n"
      ],
      "metadata": {
        "id": "XJ-uDTBYv6r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instaling and Loading packages"
      ],
      "metadata": {
        "id": "XLVpS42srawQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible versions\n",
        "!pip install torch==2.1.0+cu117 torchvision==0.16.0+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "3IHybQpLrm6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Dataset Exploration"
      ],
      "metadata": {
        "id": "WYa9f1pYAZss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import six\n",
        "\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32',\n",
        "                  padding='pre', truncating='pre', value=0.):\n",
        "    if not hasattr(sequences, '__len__'):\n",
        "        raise ValueError('`sequences` must be iterable.')\n",
        "    lengths = []\n",
        "    for x in sequences:\n",
        "        if not hasattr(x, '__len__'):\n",
        "            raise ValueError('`sequences` must be a list of iterables. '\n",
        "                             'Found non-iterable: ' + str(x))\n",
        "        lengths.append(len(x))\n",
        "\n",
        "    num_samples = len(sequences)\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "\n",
        "    # take the sample shape from the first non empty sequence\n",
        "    # checking for consistency in the main loop below.\n",
        "    sample_shape = tuple()\n",
        "    for s in sequences:\n",
        "        if len(s) > 0:\n",
        "            sample_shape = np.asarray(s).shape[1:]\n",
        "            break\n",
        "\n",
        "    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(dtype, np.unicode_)\n",
        "    if isinstance(value, six.string_types) and dtype != object and not is_dtype_str:\n",
        "        raise ValueError(\"`dtype` {} is not compatible with `value`'s type: {}\\n\"\n",
        "                         \"You should set `dtype=object` for variable length strings.\"\n",
        "                         .format(dtype, type(value)))\n",
        "\n",
        "    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if not len(s):\n",
        "            continue  # empty list/array was found\n",
        "        if truncating == 'pre':\n",
        "            trunc = s[-maxlen:]\n",
        "        elif truncating == 'post':\n",
        "            trunc = s[:maxlen]\n",
        "        else:\n",
        "            raise ValueError('Truncating type \"%s\" '\n",
        "                             'not understood' % truncating)\n",
        "\n",
        "        # check `trunc` has expected shape\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "        if trunc.shape[1:] != sample_shape:\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s '\n",
        "                             'is different from expected shape %s' %\n",
        "                             (trunc.shape[1:], idx, sample_shape))\n",
        "\n",
        "        if padding == 'post':\n",
        "            x[idx, :len(trunc)] = trunc\n",
        "        elif padding == 'pre':\n",
        "            x[idx, -len(trunc):] = trunc\n",
        "        else:\n",
        "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
        "    return x\n",
        "\n",
        "def to_categorical(y, num_classes=None, dtype='float32'):\n",
        "    y = np.array(y, dtype='int')\n",
        "    input_shape = y.shape\n",
        "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
        "        input_shape = tuple(input_shape[:-1])\n",
        "    y = y.ravel()\n",
        "    if not num_classes:\n",
        "        num_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    output_shape = input_shape + (num_classes,)\n",
        "    categorical = np.reshape(categorical, output_shape)\n",
        "    return categorical\n",
        "\n",
        "class EchoData():\n",
        "\n",
        "    def __init__(self, series_length=40000, batch_size=32,\n",
        "                 echo_step=3, truncated_length=10, seed=None):\n",
        "\n",
        "        self.series_length = series_length\n",
        "        self.truncated_length = truncated_length\n",
        "        self.n_batches = series_length//truncated_length\n",
        "\n",
        "        self.echo_step = echo_step\n",
        "        self.batch_size = batch_size\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "        self.x_batch = None\n",
        "        self.y_batch = None\n",
        "        self.x_chunks = []\n",
        "        self.y_chunks = []\n",
        "        self.generate_new_series()\n",
        "        self.prepare_batches()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index == 0:\n",
        "            self.generate_new_series()\n",
        "            self.prepare_batches()\n",
        "        return self.x_chunks[index], self.y_chunks[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "    def generate_new_series(self):\n",
        "        x = np.random.choice(\n",
        "            2,\n",
        "            size=(self.batch_size, self.series_length),\n",
        "            p=[0.5, 0.5])\n",
        "        y = np.roll(x, self.echo_step, axis=1)\n",
        "        y[:, 0:self.echo_step] = 0\n",
        "        self.x_batch = x\n",
        "        self.y_batch = y\n",
        "\n",
        "    def prepare_batches(self):\n",
        "        x = np.expand_dims(self.x_batch, axis=-1)\n",
        "        y = np.expand_dims(self.y_batch, axis=-1)\n",
        "        self.x_chunks = np.split(x, self.n_batches, axis=1)\n",
        "        self.y_chunks = np.split(y, self.n_batches, axis=1)\n",
        "\n",
        "class TemporalOrderExp6aSequence():\n",
        "    \"\"\"\n",
        "    From Hochreiter&Schmidhuber(1997):\n",
        "\n",
        "        The goal is to classify sequences. Elements and targets are represented locally\n",
        "        (input vectors with only one non-zero bit). The sequence starts with an E, ends\n",
        "        with a B (the \"trigger symbol\") and otherwise consists of randomly chosen symbols\n",
        "        from the set {a, b, c, d} except for two elements at positions t1 and t2 that are\n",
        "        either X or Y . The sequence length is randomly chosen between 100 and 110, t1 is\n",
        "        randomly chosen between 10 and 20, and t2 is randomly chosen between 50 and 60.\n",
        "        There are 4 sequence classes Q, R, S, U which depend on the temporal order of X and Y.\n",
        "        The rules are:\n",
        "            X, X -> Q,\n",
        "            X, Y -> R,\n",
        "            Y , X -> S,\n",
        "            Y , Y -> U.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, length_range=(100, 111), t1_range=(10, 21), t2_range=(50, 61),\n",
        "                 batch_size=32, seed=None):\n",
        "\n",
        "        self.classes = ['Q', 'R', 'S', 'U']\n",
        "        self.n_classes = len(self.classes)\n",
        "\n",
        "        self.relevant_symbols = ['X', 'Y']\n",
        "        self.distraction_symbols = ['a', 'b', 'c', 'd']\n",
        "        self.start_symbol = 'B'\n",
        "        self.end_symbol = 'E'\n",
        "\n",
        "        self.length_range = length_range\n",
        "        self.t1_range = t1_range\n",
        "        self.t2_range = t2_range\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        all_symbols = self.relevant_symbols + self.distraction_symbols + \\\n",
        "                      [self.start_symbol] + [self.end_symbol]\n",
        "        self.n_symbols = len(all_symbols)\n",
        "        self.s_to_idx = {s: n for n, s in enumerate(all_symbols)}\n",
        "        self.idx_to_s = {n: s for n, s in enumerate(all_symbols)}\n",
        "\n",
        "        self.c_to_idx = {c: n for n, c in enumerate(self.classes)}\n",
        "        self.idx_to_c = {n: c for n, c in enumerate(self.classes)}\n",
        "\n",
        "    def generate_pair(self):\n",
        "        length = np.random.randint(self.length_range[0], self.length_range[1])\n",
        "        t1 = np.random.randint(self.t1_range[0], self.t1_range[1])\n",
        "        t2 = np.random.randint(self.t2_range[0], self.t2_range[1])\n",
        "\n",
        "        x = np.random.choice(self.distraction_symbols, length)\n",
        "        x[0] = self.start_symbol\n",
        "        x[-1] = self.end_symbol\n",
        "\n",
        "        y = np.random.choice(self.classes)\n",
        "        if y == 'Q':\n",
        "            x[t1], x[t2] = self.relevant_symbols[0], self.relevant_symbols[0]\n",
        "        elif y == 'R':\n",
        "            x[t1], x[t2] = self.relevant_symbols[0], self.relevant_symbols[1]\n",
        "        elif y == 'S':\n",
        "            x[t1], x[t2] = self.relevant_symbols[1], self.relevant_symbols[0]\n",
        "        else:\n",
        "            x[t1], x[t2] = self.relevant_symbols[1], self.relevant_symbols[1]\n",
        "\n",
        "        return ''.join(x), y\n",
        "\n",
        "    # encoding/decoding single instance version\n",
        "\n",
        "    def encode_x(self, x):\n",
        "        idx_x = [self.s_to_idx[s] for s in x]\n",
        "        return to_categorical(idx_x, num_classes=self.n_symbols)\n",
        "\n",
        "    def encode_y(self, y):\n",
        "        idx_y = self.c_to_idx[y]\n",
        "        return to_categorical(idx_y, num_classes=self.n_classes)\n",
        "\n",
        "    def decode_x(self, x):\n",
        "        x = x[np.sum(x, axis=1) > 0]    # remove padding\n",
        "        return ''.join([self.idx_to_s[pos] for pos in np.argmax(x, axis=1)])\n",
        "\n",
        "    def decode_y(self, y):\n",
        "        return self.idx_to_c[np.argmax(y)]\n",
        "\n",
        "    # encoding/decoding batch versions\n",
        "\n",
        "    def encode_x_batch(self, x_batch):\n",
        "        return pad_sequences([self.encode_x(x) for x in x_batch],\n",
        "                             maxlen=self.length_range[1])\n",
        "\n",
        "    def encode_y_batch(self, y_batch):\n",
        "        return np.array([self.encode_y(y) for y in y_batch])\n",
        "\n",
        "    def decode_x_batch(self, x_batch):\n",
        "        return [self.decode_x(x) for x in x_batch]\n",
        "\n",
        "    def decode_y_batch(self, y_batch):\n",
        "        return [self.idx_to_c[pos] for pos in np.argmax(y_batch, axis=1)]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Let's assume 1000 sequences as the size of data. \"\"\"\n",
        "        return int(1000. / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_x, batch_y = [], []\n",
        "        for _ in range(self.batch_size):\n",
        "            x, y = self.generate_pair()\n",
        "            batch_x.append(x)\n",
        "            batch_y.append(y)\n",
        "        return self.encode_x_batch(batch_x), self.encode_y_batch(batch_y)\n",
        "\n",
        "    class DifficultyLevel:\n",
        "        \"\"\" On HARD, settings are identical to the original settings from the '97 paper.\"\"\"\n",
        "        EASY, NORMAL, MODERATE, HARD, NIGHTMARE = range(5)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_predefined_generator(difficulty_level, batch_size=32, seed=8382):\n",
        "        EASY = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n",
        "        NORMAL = TemporalOrderExp6aSequence.DifficultyLevel.NORMAL\n",
        "        MODERATE = TemporalOrderExp6aSequence.DifficultyLevel.MODERATE\n",
        "        HARD = TemporalOrderExp6aSequence.DifficultyLevel.HARD\n",
        "\n",
        "        if difficulty_level == EASY:\n",
        "            length_range = (7, 9)\n",
        "            t1_range = (1, 3)\n",
        "            t2_range = (4, 6)\n",
        "        elif difficulty_level == NORMAL:\n",
        "            length_range = (30, 41)\n",
        "            t1_range = (2, 6)\n",
        "            t2_range = (20, 28)\n",
        "        elif difficulty_level == MODERATE:\n",
        "            length_range = (60, 81)\n",
        "            t1_range = (10, 21)\n",
        "            t2_range = (45, 55)\n",
        "        elif difficulty_level == HARD:\n",
        "            length_range = (100, 111)\n",
        "            t1_range = (10, 21)\n",
        "            t2_range = (50, 61)\n",
        "        else:\n",
        "            length_range = (300, 501)\n",
        "            t1_range = (10, 81)\n",
        "            t2_range = (250, 291)\n",
        "        return TemporalOrderExp6aSequence(length_range, t1_range, t2_range,\n",
        "                                          batch_size, seed)\n"
      ],
      "metadata": {
        "id": "Ov0q_JEgCotj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data generator.\n",
        "datagenerator = TemporalOrderExp6aSequence()\n",
        "example_generator = datagenerator.get_predefined_generator(\n",
        "    # The first argument is the difficulty level of the classification task.\n",
        "    difficulty_level=datagenerator.DifficultyLevel.EASY,\n",
        "    # The second argument is the number of sequences generated in each batch of data.\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "example_batch = example_generator[1]\n",
        "print(f'The return type is a {type(example_batch)} with length {len(example_batch)}.')\n",
        "print(f'The first item in the tuple is the batch of sequences with shape {example_batch[0].shape}.')\n",
        "print(f'The first element in the batch of sequences is:\\n {example_batch[0][0, :, :]}')\n",
        "print(f'The second item in the tuple is the corresponding batch of class labels with shape {example_batch[1].shape}.')\n",
        "print(f'The first element in the batch of class labels is:\\n {example_batch[1][0, :]}')"
      ],
      "metadata": {
        "id": "qOADcRDQAcMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoding the first sequence\n",
        "sequence_decoded = example_generator.decode_x(example_batch[0][0, :, :])\n",
        "print(f'The sequence is: {sequence_decoded}')\n",
        "\n",
        "# Decoding the class label of the first sequence\n",
        "class_label_decoded = example_generator.decode_y(example_batch[1][0])\n",
        "print(f'The class label is: {class_label_decoded}')"
      ],
      "metadata": {
        "id": "hWfQ6jXdqLVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the RNN-LSTM Models"
      ],
      "metadata": {
        "id": "sYBnz_DhFLCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set the random seed for reproducible results\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # This just calls the base class constructor\n",
        "        # Todo : implement RNN using pytorch nn module torch.nn.RNN(input_size, hidden_size, nonlinearity, batch_first)\n",
        "        super().__init__()\n",
        "        self.rnn = ##< Your code> add RNN layer\n",
        "        self.linear = ##< Your code> add a linear layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.rnn(x)[0]\n",
        "        x = self.linear(h)\n",
        "        return x\n",
        "\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Todo : implement LSTM using pytorch nn module torch.nn.LSTM(input_size, hidden_size, batch_first)\n",
        "        super().__init__()\n",
        "        self.lstm = ##< Your code> add LSTM layer\n",
        "        self.linear = ##< Your code> add a linear layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.lstm(x)[0]\n",
        "        x = self.linear(h)\n",
        "        return x\n",
        "\n",
        "    def get_states_across_time(self, x):\n",
        "        h_c = None\n",
        "        h_list, c_list = list(), list()\n",
        "        with torch.no_grad():\n",
        "            for t in range(x.size(1)):\n",
        "                h_c = self.lstm(x[:, [t], :], h_c)[1]\n",
        "                h_list.append(h_c[0])\n",
        "                c_list.append(h_c[1])\n",
        "            h = torch.cat(h_list)\n",
        "            c = torch.cat(c_list)\n",
        "        return h, c"
      ],
      "metadata": {
        "id": "ZlazisNWrK3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Training Loop"
      ],
      "metadata": {
        "id": "uTz-BDEPsWpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data_gen, criterion, optimizer, device):\n",
        "    # Set the model to training mode. This will turn on layers that would\n",
        "    # otherwise behave differently during evaluation, such as dropout.\n",
        "    model.train()\n",
        "\n",
        "    # Store the number of sequences that were classified correctly\n",
        "    num_correct = 0\n",
        "\n",
        "    # Iterate over every batch of sequences. Note that the length of a data generator\n",
        "    # is defined as the number of batches required to produce a total of roughly 1000\n",
        "    # sequences given a batch size.\n",
        "    for batch_idx in range(len(train_data_gen)):\n",
        "\n",
        "        # Request a batch of sequences and class labels, convert them into tensors\n",
        "        # of the correct type, and then send them to the appropriate device.\n",
        "        data, target = train_data_gen[batch_idx]\n",
        "        data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
        "\n",
        "        # Perform the forward pass of the model\n",
        "        output = ##< Your code> forward pass\n",
        "\n",
        "        # Pick only the output corresponding to last sequence element (input is pre padded)\n",
        "        output = output[:, -1, :]\n",
        "\n",
        "        # Compute the value of the loss for this batch. For loss functions like CrossEntropyLoss,\n",
        "        # the second argument is actually expected to be a tensor of class indices rather than\n",
        "        # one-hot encoded class labels. One approach is to take advantage of the one-hot encoding\n",
        "        # of the target and call argmax along its second dimension to create a tensor of shape\n",
        "        # (batch_size) containing the index of the class label that was hot for each sequence.\n",
        "        target = target.argmax(dim=1)\n",
        "\n",
        "        loss = ##< Your code> call criterion to compute the loss\n",
        "\n",
        "        # Clear the gradient buffers of the optimized parameters.\n",
        "        # Otherwise, gradients from the previous batch would be accumulated.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ##< Your code> compute the backward pass\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred = output.argmax(dim=1)\n",
        "        num_correct += (y_pred == target).sum().item()\n",
        "\n",
        "    return num_correct, loss.item()"
      ],
      "metadata": {
        "id": "9mRhyFnzsaq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Testing Loop\n"
      ],
      "metadata": {
        "id": "LNBRBaLUsj8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_data_gen, criterion, device):\n",
        "    # Set the model to evaluation mode. This will turn off layers that would\n",
        "    # otherwise behave differently during training, such as dropout.\n",
        "    model.eval()\n",
        "\n",
        "    # Store the number of sequences that were classified correctly\n",
        "    num_correct = 0\n",
        "\n",
        "    # A context manager is used to disable gradient calculations during inference\n",
        "    # to reduce memory usage, as we typically don't need the gradients at this point.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(len(test_data_gen)):\n",
        "            data, target = test_data_gen[batch_idx]\n",
        "            data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            # Pick only the output corresponding to last sequence element (input is pre padded)\n",
        "            output = output[:, -1, :]\n",
        "\n",
        "            target = target.argmax(dim=1)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            y_pred = output.argmax(dim=1)\n",
        "            num_correct += (y_pred == target).sum().item()\n",
        "\n",
        "    return num_correct, loss.item()"
      ],
      "metadata": {
        "id": "jJ65KkJTsacM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it All Together"
      ],
      "metadata": {
        "id": "faDz8ZgwsvZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs, verbose=True):\n",
        "    # Automatically determine the device that PyTorch should use for computation\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Move model to the device which will be used for train and test\n",
        "    model.to(device)\n",
        "\n",
        "    # Track the value of the loss function and model accuracy across epochs\n",
        "    history_train = {'loss': [], 'acc': []}\n",
        "    history_test = {'loss': [], 'acc': []}\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # Run the training loop and calculate the accuracy.\n",
        "        # Remember that the length of a data generator is the number of batches,\n",
        "        # so we multiply it by the batch size to recover the total number of sequences.\n",
        "        num_correct, loss = train(model, train_data_gen, criterion, optimizer, device)\n",
        "        accuracy = float(num_correct) / (len(train_data_gen) * train_data_gen.batch_size) * 100\n",
        "        history_train['loss'].append(loss)\n",
        "        history_train['acc'].append(accuracy)\n",
        "\n",
        "        # Do the same for the testing loop\n",
        "        num_correct, loss = test(model, test_data_gen, criterion, device)\n",
        "        accuracy = float(num_correct) / (len(test_data_gen) * test_data_gen.batch_size) * 100\n",
        "        history_test['loss'].append(loss)\n",
        "        history_test['acc'].append(accuracy)\n",
        "\n",
        "        if verbose or epoch + 1 == max_epochs:\n",
        "            print(f'[Epoch {epoch + 1}/{max_epochs}]'\n",
        "                  f\" loss: {history_train['loss'][-1]:.4f}, acc: {history_train['acc'][-1]:2.2f}%\"\n",
        "                  f\" - test_loss: {history_test['loss'][-1]:.4f}, test_acc: {history_test['acc'][-1]:2.2f}%\")\n",
        "\n",
        "    # Generate diagnostic plots for the loss and accuracy\n",
        "    fig, axes = plt.subplots(ncols=2, figsize=(9, 4.5))\n",
        "    for ax, metric in zip(axes, ['loss', 'acc']):\n",
        "        ax.plot(history_train[metric])\n",
        "        ax.plot(history_test[metric])\n",
        "        ax.set_xlabel('epoch', fontsize=12)\n",
        "        ax.set_ylabel(metric, fontsize=12)\n",
        "        ax.legend(['Train', 'Test'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0GsVkb0rs2Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple RNN: 10 Epochs\n"
      ],
      "metadata": {
        "id": "ETtFm48ltJ1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the training and test data generators\n",
        "difficulty     = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n",
        "batch_size     = 32\n",
        "train_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "test_data_gen  = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "\n",
        "# Setup the RNN and training settings\n",
        "input_size  = train_data_gen.n_symbols\n",
        "hidden_size = 4\n",
        "output_size = train_data_gen.n_classes\n",
        "model       = SimpleRNN(input_size, hidden_size, output_size)\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "max_epochs  = 10\n",
        "\n",
        "# Train the model\n",
        "model = train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs)"
      ],
      "metadata": {
        "id": "9purPpE9tM3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simple LSTM: 10 Epochs\n"
      ],
      "metadata": {
        "id": "3Y_vS8nVvTJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the training and test data generators\n",
        "difficulty     = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n",
        "batch_size     = 32\n",
        "train_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "test_data_gen  = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "\n",
        "# Setup the RNN and training settings\n",
        "input_size  = train_data_gen.n_symbols\n",
        "hidden_size = 4\n",
        "output_size = train_data_gen.n_classes\n",
        "model       = SimpleLSTM(input_size, hidden_size, output_size)\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "max_epochs  = 10\n",
        "\n",
        "# Train the model\n",
        "model = train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs)"
      ],
      "metadata": {
        "id": "N3qHse_Ivg8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN: Increasing Epoch to 100\n"
      ],
      "metadata": {
        "id": "ic62Iv2Kv6X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the training and test data generators\n",
        "difficulty     = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n",
        "batch_size     = 32\n",
        "train_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "test_data_gen  = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "\n",
        "# Setup the RNN and training settings\n",
        "input_size  = train_data_gen.n_symbols\n",
        "hidden_size = 4\n",
        "output_size = train_data_gen.n_classes\n",
        "model       = SimpleRNN(input_size, hidden_size, output_size)\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "max_epochs  = 100\n",
        "\n",
        "# Train the model\n",
        "model = train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs, verbose=False)"
      ],
      "metadata": {
        "id": "Rl5p2u6wv7c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM: Increasing Epoch to 100"
      ],
      "metadata": {
        "id": "Se8ej1jHwMI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the training and test data generators\n",
        "difficulty     = TemporalOrderExp6aSequence.DifficultyLevel.EASY\n",
        "batch_size     = 32\n",
        "train_data_gen = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "test_data_gen  = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, batch_size)\n",
        "\n",
        "# Setup the RNN and training settings\n",
        "input_size  = train_data_gen.n_symbols\n",
        "hidden_size = 4\n",
        "output_size = train_data_gen.n_classes\n",
        "model       = SimpleLSTM(input_size, hidden_size, output_size)\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "max_epochs  = 100\n",
        "\n",
        "# Train the model\n",
        "model = train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs, verbose=False)"
      ],
      "metadata": {
        "id": "GAkqVR1DwRV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n"
      ],
      "metadata": {
        "id": "9NDavQakwb-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import random\n",
        "\n",
        "def evaluate_model(model, difficulty, seed=9001, verbose=False):\n",
        "    # Define a dictionary that maps class indices to labels\n",
        "    class_idx_to_label = {0: 'Q', 1: 'R', 2: 'S', 3: 'U'}\n",
        "\n",
        "    # Create a new data generator\n",
        "    data_generator = TemporalOrderExp6aSequence.get_predefined_generator(difficulty, seed=seed)\n",
        "\n",
        "    # Track the number of times a class appears\n",
        "    count_classes = collections.Counter()\n",
        "\n",
        "    # Keep correctly classified and misclassified sequences, and their\n",
        "    # true and predicted class labels, for diagnostic information.\n",
        "    correct = []\n",
        "    incorrect = []\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(len(data_generator)):\n",
        "            data, target = test_data_gen[batch_idx]\n",
        "            data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
        "\n",
        "            data_decoded = data_generator.decode_x_batch(data.cpu().numpy())\n",
        "            target_decoded = data_generator.decode_y_batch(target.cpu().numpy())\n",
        "\n",
        "            output = model(data)\n",
        "            output = output[:, -1, :]\n",
        "\n",
        "            target = target.argmax(dim=1)\n",
        "            y_pred = output.argmax(dim=1)\n",
        "            y_pred_decoded = [class_idx_to_label[y.item()] for y in y_pred]\n",
        "\n",
        "            count_classes.update(target_decoded)\n",
        "            for i, (truth, prediction) in enumerate(zip(target_decoded, y_pred_decoded)):\n",
        "                if truth == prediction:\n",
        "                    correct.append((data_decoded[i], truth, prediction))\n",
        "                else:\n",
        "                    incorrect.append((data_decoded[i], truth, prediction))\n",
        "\n",
        "    num_sequences = sum(count_classes.values())\n",
        "    accuracy = float(len(correct)) / num_sequences * 100\n",
        "    print(f'The accuracy of the model is measured to be {accuracy:.2f}%.\\n')\n",
        "\n",
        "    # Report the accuracy by class\n",
        "    for label in sorted(count_classes):\n",
        "        num_correct = sum(1 for _, truth, _ in correct if truth == label)\n",
        "        print(f'{label}: {num_correct} / {count_classes[label]} correct')\n",
        "\n",
        "    # Report some random sequences for examination\n",
        "    print('\\nHere are some example sequences:')\n",
        "    for i in range(10):\n",
        "        sequence, truth, prediction = correct[random.randrange(0, 10)]\n",
        "        print(f'{sequence} -> {truth} was labelled {prediction}')\n",
        "\n",
        "    # Report misclassified sequences for investigation\n",
        "    if incorrect and verbose:\n",
        "        print('\\nThe following sequences were misclassified:')\n",
        "        for sequence, truth, prediction in incorrect:\n",
        "            print(f'{sequence} -> {truth} was labelled {prediction}')\n",
        "    else:\n",
        "        print('\\nThere were no misclassified sequences.')"
      ],
      "metadata": {
        "id": "vuHs0U8twn-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, difficulty)"
      ],
      "metadata": {
        "id": "3IUVIESQwrID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question:\n",
        "\n",
        "\n",
        "*   Compare the results(loss and accuracy) for RNN and LSTM on 5 epochs\n",
        "*   What are the advantages of using an LSTM over a standard RNN?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hMJwzy4g1ku9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "\n",
        "- https://github.com/Atcold/pytorch-Deep-Learning\n",
        "- Dive into Deep learning [link](https://www.d2l.ai/chapter_multilayer-perceptrons/index.html)\n",
        "- https://cs231n.github.io/convolutional-networks/\n",
        "- https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
        "- https://github.com/jerofad/pytorch-Deep-Learning-Minicourse"
      ],
      "metadata": {
        "id": "bMlVd5lmp_uZ"
      }
    }
  ]
}